I used GitHub Copilot to help me build parts of my data cleaning script, mainly the first versions of my functions. When I wrote comments that explained what I wanted the function to do, Copilot generated a basic structure for me. This happened with the load_data function and the first attempt at cleaning column names. Copilot gave me a simple layout with the function name and the read_csv line which made it easier for me to get started instead of building everything from scratch.

Even though Copilot helped, I still had to change a lot of what it gave me. Some of the suggestions did not match the real structure of my dataset. A good example is when Copilot suggested using a method that does not exist in pandas. I replaced that part with code that actually works. I also had to change the logic in the functions that handled missing values and invalid rows because my dataset used column names like price and qty instead of price and quantity. These changes showed me that Copilot can write code really fast but it does not always understand the real context of the problem. I had to think through every step to make sure the script worked the way it should.

What I learned from this assignment is that Copilot can save a lot of time but it does not replace real problem solving. I still needed to understand my dataset and make decisions about how to clean it. I learned how important it is to standardize column names and convert values to the correct types before trying to filter anything. I also learned that debugging is a big part of working with messy data. Even though Copilot helped me move faster, I was the one who had to fix the mistakes and adjust everything to match the assignment. This project helped me understand how to use AI tools responsibly while still staying in control of the code and the final results.